# ---------------------------------------------------------------------------
# PENDO CLIMATE ECONOMY ASSISTANT - AGENT API SERVICE ENVIRONMENT VARIABLES
# ---------------------------------------------------------------------------
# These variables are used by the FastAPI agent service.
# Optimized for Ollama-first deployment with OpenAI as fallback.

# ---------------------------------------------------------------------------
# LLM CONFIGURATION (Primary: Ollama)
# ---------------------------------------------------------------------------

# The provider for your LLM
# Set this to either ollama (primary), openai (fallback), or openrouter
# This is needed on top of the base URL for Mem0 (long term memory)
LLM_PROVIDER=ollama

# Base URL for the OpenAI compatible instance 
# Ollama (local development): http://localhost:11434/v1
# Ollama (Docker/production): http://host.docker.internal:11434/v1
# OpenAI: https://api.openai.com/v1
# OpenRouter: https://openrouter.ai/api/v1
LLM_BASE_URL=http://localhost:11434/v1

# API Key configuration
# Ollama: Set to "ollama" unless you specifically configured an API key
# OpenAI: https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# OpenRouter: Get your API Key here after registering: https://openrouter.ai/keys
LLM_API_KEY=ollama

# The LLM you want to use for the agents. Make sure this LLM supports tools!
# Ollama examples: llama3.2:3b, qwen2.5:7b-instruct, qwen2.5:14b-instruct-8k
# OpenAI example: gpt-4o-mini
# OpenRouter example: anthropic/claude-3.7-sonnet
LLM_CHOICE=llama3.2:3b

# The LLM you want to use for image analysis.
# Make sure this LLM supports vision!
# Ollama examples: llava:7b, llava:13b, bakllava:7b
# OpenAI example: gpt-4o-mini
# OpenRouter example: anthropic/claude-3.7-sonnet
VISION_LLM_CHOICE=llava:7b

# OpenAI Fallback Configuration (optional)
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL_CHOICE=gpt-4o-mini

# ---------------------------------------------------------------------------
# EMBEDDING CONFIGURATION (Primary: Ollama)
# ---------------------------------------------------------------------------

# The provider for your embedding model
# Set this to either ollama (primary) or openai (fallback)
# This is needed on top of the base URL for Mem0 (long term memory)
EMBEDDING_PROVIDER=ollama

# Base URL for the OpenAI compatible instance that has embedding models
# Ollama (local): http://localhost:11434/v1
# Ollama (Docker): http://host.docker.internal:11434/v1
# OpenAI: https://api.openai.com/v1
EMBEDDING_BASE_URL=http://localhost:11434/v1

# Embedding API Key
# Ollama: Set to "ollama" unless you specifically configured an API key
# OpenAI: Your OpenAI API key
EMBEDDING_API_KEY=ollama

# The embedding model you want to use for RAG.
# Make sure the embeddings column in your database has the same dimensions!
# Ollama examples: nomic-embed-text, all-minilm, mxbai-embed-large
# OpenAI example: text-embedding-3-small
EMBEDDING_MODEL_CHOICE=nomic-embed-text

# ---------------------------------------------------------------------------
# DATABASE CONFIGURATION (Supabase)
# ---------------------------------------------------------------------------

# Postgres DB URL used for Mem0 and application data
# Format: postgresql://[user]:[password]@[host]:[port]/[database_name]
# For Supabase Postgres connection, you can find this in "Connect" -> Transaction pooler
DATABASE_URL=postgresql://postgres.YOUR_PROJECT_ID:YOUR_PASSWORD@aws-0-us-east-1.pooler.supabase.com:6543/postgres

# Supabase configuration
# Get these from your Supabase project settings -> API
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_URL=https://YOUR_PROJECT_ID.supabase.co
SUPABASE_SERVICE_KEY=YOUR_SERVICE_ROLE_KEY_HERE

# ---------------------------------------------------------------------------
# WEB SEARCH CONFIGURATION (Optional)
# ---------------------------------------------------------------------------

# Set your Brave API key if using Brave for agent web search
# Get your key by going to the following link after signing up for Brave:
# https://api.search.brave.com/app/keys
BRAVE_API_KEY=YOUR_BRAVE_API_KEY_HERE

# Set the SearXNG endpoint if using SearXNG for agent web search
# For local deployment: http://localhost:8081
# For Docker deployment: http://searxng:8080
SEARXNG_BASE_URL=

# ---------------------------------------------------------------------------
# OBSERVABILITY CONFIGURATION (Optional)
# ---------------------------------------------------------------------------

# Langfuse configuration for agent observability
# Get these from your Langfuse project settings
# https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=YOUR_LANGFUSE_PUBLIC_KEY
LANGFUSE_SECRET_KEY=YOUR_LANGFUSE_SECRET_KEY
LANGFUSE_HOST=https://cloud.langfuse.com

# ---------------------------------------------------------------------------
# DEPLOYMENT CONFIGURATION
# ---------------------------------------------------------------------------

# Environment setting (development, staging, production)
ENVIRONMENT=production

# Port configuration (default: 8001)
PORT=8001

# CORS origins (comma-separated list)
CORS_ORIGINS=https://cea.yourdomain.com,https://www.cea.yourdomain.com 