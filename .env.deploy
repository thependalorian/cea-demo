# ---------------------------------------------------------------------------
# PENDO CLIMATE ECONOMY ASSISTANT - AGENT API SERVICE ENVIRONMENT VARIABLES
# ---------------------------------------------------------------------------
# These variables are used by the FastAPI agent service.
# Optimized for Ollama-first deployment with OpenAI as fallback.

# ---------------------------------------------------------------------------
# LLM CONFIGURATION (Primary: Ollama)
# ---------------------------------------------------------------------------

# The provider for your LLM
# Set this to either ollama (primary), openai (fallback), or openrouter
# This is needed on top of the base URL for Mem0 (long term memory)
LLM_PROVIDER=ollama

# Base URL for the OpenAI compatible instance 
# Ollama (local development): http://localhost:11434/v1
# Ollama (Docker/production): http://host.docker.internal:11434/v1
# OpenAI: https://api.openai.com/v1
# OpenRouter: https://openrouter.ai/api/v1
LLM_BASE_URL=http://localhost:11434/v1

# API Key configuration
# Ollama: Set to "ollama" unless you specifically configured an API key
# OpenAI: https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# OpenRouter: Get your API Key here after registering: https://openrouter.ai/keys
LLM_API_KEY=ollama

# The LLM you want to use for the agents. Make sure this LLM supports tools!
# Ollama examples: llama3.2:3b, qwen2.5:7b-instruct, qwen2.5:14b-instruct-8k
# OpenAI example: gpt-4o-mini
# OpenRouter example: anthropic/claude-3.7-sonnet
LLM_CHOICE=llama3.2:3b

# The LLM you want to use for image analysis.
# Make sure this LLM supports vision!
# Ollama examples: llava:7b, llava:13b, bakllava:7b
# OpenAI example: gpt-4o-mini
# OpenRouter example: anthropic/claude-3.7-sonnet
VISION_LLM_CHOICE=llava:7b

# OpenAI Fallback Configuration (optional)
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL_CHOICE=gpt-4o-mini

# ---------------------------------------------------------------------------
# EMBEDDING CONFIGURATION (Primary: Ollama)
# ---------------------------------------------------------------------------

# The provider for your embedding model
# Set this to either ollama (primary) or openai (fallback)
# This is needed on top of the base URL for Mem0 (long term memory)
EMBEDDING_PROVIDER=ollama

# Base URL for the OpenAI compatible instance that has embedding models
# Ollama (local): http://localhost:11434/v1
# Ollama (Docker): http://host.docker.internal:11434/v1
# OpenAI: https://api.openai.com/v1
EMBEDDING_BASE_URL=http://localhost:11434/v1

# Embedding API Key
# Ollama: Set to "ollama" unless you specifically configured an API key
# OpenAI: Your OpenAI API key
EMBEDDING_API_KEY=ollama

# The embedding model you want to use for RAG.
# Make sure the embeddings column in your database has the same dimensions!
# Ollama examples: nomic-embed-text, all-minilm, mxbai-embed-large
# OpenAI example: text-embedding-3-small
EMBEDDING_MODEL_CHOICE=nomic-embed-text

# ---------------------------------------------------------------------------
# DATABASE CONFIGURATION (Supabase)
# ---------------------------------------------------------------------------

# Postgres DB URL used for Mem0 and application data
# Format: postgresql://[user]:[password]@[host]:[port]/[database_name]
# For Supabase Postgres connection, you can find this in "Connect" -> Transaction pooler
DATABASE_URL=postgresql://postgres.YOUR_PROJECT_ID:YOUR_PASSWORD@aws-0-us-east-1.pooler.supabase.com:6543/postgres

# Supabase configuration
# Get these from your Supabase project settings -> API
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_URL=https://YOUR_PROJECT_ID.supabase.co
SUPABASE_SERVICE_KEY=YOUR_SERVICE_ROLE_KEY_HERE

# ---------------------------------------------------------------------------
# WEB SEARCH CONFIGURATION (Optional)
# ---------------------------------------------------------------------------

# Set your Brave API key if using Brave for agent web search
# Get your key by going to the following link after signing up for Brave:
# https://api.search.brave.com/app/keys
BRAVE_API_KEY=YOUR_BRAVE_API_KEY_HERE

# Set the SearXNG endpoint if using SearXNG for agent web search
# For local deployment: http://localhost:8081
# For Docker deployment: http://searxng:8080
SEARXNG_BASE_URL=

# ---------------------------------------------------------------------------
# OBSERVABILITY CONFIGURATION (Optional)
# ---------------------------------------------------------------------------

# Langfuse configuration for agent observability
# Get these from your Langfuse project settings
# https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=YOUR_LANGFUSE_PUBLIC_KEY
LANGFUSE_SECRET_KEY=YOUR_LANGFUSE_SECRET_KEY
LANGFUSE_HOST=https://cloud.langfuse.com

# ---------------------------------------------------------------------------
# DEPLOYMENT CONFIGURATION
# ---------------------------------------------------------------------------

# Environment setting (development, staging, production)
ENVIRONMENT=production

# Port configuration (default: 8001)
PORT=8001

# CORS origins (comma-separated list)
CORS_ORIGINS=https://cea.yourdomain.com,https://www.cea.yourdomain.com # ---------------------------------------------------------------------------
# PENDO CLIMATE ECONOMY ASSISTANT - RAG PIPELINE SERVICE ENVIRONMENT VARIABLES
# ---------------------------------------------------------------------------
# These variables are used by the RAG pipeline background worker.
# Optimized for Ollama-first deployment with document processing capabilities.

# ---------------------------------------------------------------------------
# RAG PIPELINE CONFIGURATION
# ---------------------------------------------------------------------------

# Environment setting
ENVIRONMENT=production

# Port configuration for RAG Pipeline API
PORT=8000

# Number of background workers for document processing
RAG_PIPELINE_WORKERS=2

# Maximum file size for uploads (in bytes)
# 10MB = 10485760, 25MB = 26214400
RAG_PIPELINE_MAX_FILE_SIZE=10485760

# Text chunking configuration
RAG_PIPELINE_CHUNK_SIZE=400
RAG_PIPELINE_CHUNK_OVERLAP=50

# ---------------------------------------------------------------------------
# DATABASE CONFIGURATION (Supabase)
# ---------------------------------------------------------------------------

# Your Supabase project URL
# Get this from: Supabase Dashboard -> Project Settings -> API
# https://supabase.com/dashboard/project/<project-id>/settings/api
SUPABASE_URL=https://YOUR_PROJECT_ID.supabase.co

# Your Supabase service role key (for server-side operations)
# Get this from: Supabase Dashboard -> Project Settings -> API
SUPABASE_SERVICE_KEY=YOUR_SERVICE_ROLE_KEY_HERE

# ---------------------------------------------------------------------------
# EMBEDDING CONFIGURATION (Primary: Ollama)
# ---------------------------------------------------------------------------

# The provider for your embedding model
# Set this to either ollama (primary) or openai (fallback)
EMBEDDING_PROVIDER=ollama

# Base URL for the embedding service
# Ollama (local development): http://localhost:11434/v1
# Ollama (Docker/production): http://host.docker.internal:11434/v1
# OpenAI: https://api.openai.com/v1
EMBEDDING_BASE_URL=http://localhost:11434/v1

# Embedding API Key
# Ollama: Set to "ollama" unless you specifically configured an API key
# OpenAI: Your OpenAI API key
EMBEDDING_API_KEY=ollama

# The embedding model you want to use for RAG.
# Make sure the embeddings column in your database has the same dimensions!
# Ollama examples: nomic-embed-text (768d), all-minilm (384d), mxbai-embed-large (1024d)
# OpenAI example: text-embedding-3-small (1536d)
EMBEDDING_MODEL_CHOICE=nomic-embed-text

# OpenAI Embedding Fallback (optional)
OPENAI_EMBEDDING_API_KEY=YOUR_OPENAI_API_KEY_HERE
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ---------------------------------------------------------------------------
# DOCUMENT PROCESSING CONFIGURATION
# ---------------------------------------------------------------------------

# Supported file types for processing (comma-separated)
SUPPORTED_FILE_TYPES=pdf,txt,docx,md

# Maximum number of pages to process per PDF
MAX_PDF_PAGES=100

# Website content extraction timeout (seconds)
WEBSITE_TIMEOUT=30

# Maximum website content length (characters)
MAX_WEBSITE_CONTENT=50000

# Resume processing configuration
RESUME_SKILL_EXTRACTION=true
RESUME_JOB_MATCHING=true

# ---------------------------------------------------------------------------
# STORAGE CONFIGURATION
# ---------------------------------------------------------------------------

# Temporary file storage directory (for processing)
TEMP_STORAGE_DIR=/app/temp

# Maximum temporary file retention (hours)
TEMP_FILE_RETENTION_HOURS=24

# File processing queue configuration
PROCESSING_QUEUE_SIZE=100
PROCESSING_TIMEOUT_MINUTES=10

# ---------------------------------------------------------------------------
# CORS AND SECURITY CONFIGURATION
# ---------------------------------------------------------------------------

# CORS origins (comma-separated list)
CORS_ORIGINS=https://cea.yourdomain.com,https://www.cea.yourdomain.com,http://localhost:3000,http://localhost:8082

# API rate limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_BURST=10

# File upload restrictions
ALLOWED_MIME_TYPES=application/pdf,text/plain,text/markdown,application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document

# ---------------------------------------------------------------------------
# MONITORING AND LOGGING
# ---------------------------------------------------------------------------

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable detailed processing logs
ENABLE_PROCESSING_LOGS=true

# Health check configuration
HEALTH_CHECK_INTERVAL=30

# Performance monitoring
ENABLE_METRICS=true
METRICS_PORT=9090

# ---------------------------------------------------------------------------
# DEPLOYMENT SPECIFIC CONFIGURATION
# ---------------------------------------------------------------------------

# For Cloud Run deployment
CLOUD_RUN_SERVICE_NAME=rag-pipeline-api
CLOUD_RUN_REGION=us-central1

# For Render deployment
RENDER_SERVICE_NAME=pendo-cea-rag-pipeline

# For local Docker deployment
DOCKER_NETWORK=pendo-network
DOCKER_VOLUME_PREFIX=pendo-cea # ---------------------------------------------------------------------------
# PENDO CLIMATE ECONOMY ASSISTANT - FRONTEND ENVIRONMENT VARIABLES
# ---------------------------------------------------------------------------
# These variables are used by the Next.js frontend application.
# Environment variables prefixed with NEXT_PUBLIC_ are exposed to the browser.

# ---------------------------------------------------------------------------
# SUPABASE CONFIGURATION (Public)
# ---------------------------------------------------------------------------

# Your Supabase project URL (public)
# Get this from: Supabase Dashboard -> Project Settings -> API
# https://supabase.com/dashboard/project/<project-id>/settings/api
NEXT_PUBLIC_SUPABASE_URL=https://YOUR_PROJECT_ID.supabase.co

# Your Supabase anon/public API key (public)
# Get this from: Supabase Dashboard -> Project Settings -> API
NEXT_PUBLIC_SUPABASE_ANON_KEY=YOUR_ANON_KEY_HERE

# ---------------------------------------------------------------------------
# API ENDPOINTS CONFIGURATION (Public)
# ---------------------------------------------------------------------------

# Agent API endpoint (public - for client-side calls)
# Local development: http://localhost:8001/api/pydantic-agent
# Production: https://agent-api.yourdomain.com/api/pydantic-agent
NEXT_PUBLIC_AGENT_ENDPOINT=http://localhost:8001/api/pydantic-agent

# RAG Pipeline API endpoint (public - for client-side calls)
# Local development: http://localhost:8000
# Production: https://rag-api.yourdomain.com
NEXT_PUBLIC_RAG_PIPELINE_ENDPOINT=http://localhost:8000

# Enable streaming for agent responses
NEXT_PUBLIC_ENABLE_STREAMING=true

# ---------------------------------------------------------------------------
# BACKEND API CONFIGURATION (Server-side only)
# ---------------------------------------------------------------------------

# Backend API URL for server-side API route calls
# Docker Compose: http://rag-pipeline-api:8000
# Local development: http://localhost:8000
# Production: https://rag-api.yourdomain.com
BACKEND_API_URL=http://rag-pipeline-api:8000

# Agent API URL for server-side calls
# Docker Compose: http://agent-api:8001
# Local development: http://localhost:8001
# Production: https://agent-api.yourdomain.com
BACKEND_AGENT_API_URL=http://agent-api:8001

# ---------------------------------------------------------------------------
# APPLICATION CONFIGURATION
# ---------------------------------------------------------------------------

# Application name and branding
NEXT_PUBLIC_APP_NAME=Pendo Climate Economy Assistant
NEXT_PUBLIC_APP_SHORT_NAME=Pendo CEA
NEXT_PUBLIC_APP_DESCRIPTION=AI-powered assistant for climate economy careers and education

# Application URLs
NEXT_PUBLIC_APP_URL=https://cea.yourdomain.com
NEXT_PUBLIC_SUPPORT_EMAIL=support@yourdomain.com

# Feature flags
NEXT_PUBLIC_ENABLE_RESUME_UPLOAD=true
NEXT_PUBLIC_ENABLE_JOB_MATCHING=true
NEXT_PUBLIC_ENABLE_ADMIN_PANEL=true
NEXT_PUBLIC_ENABLE_ANALYTICS=true

# ---------------------------------------------------------------------------
# DEPLOYMENT CONFIGURATION
# ---------------------------------------------------------------------------

# Environment setting
NODE_ENV=production
NEXT_PUBLIC_ENVIRONMENT=production

# Port configuration (for Docker)
PORT=3000

# Build configuration
NEXT_TELEMETRY_DISABLED=1

# ---------------------------------------------------------------------------
# SECURITY CONFIGURATION
# ---------------------------------------------------------------------------

# CORS origins (for API routes)
CORS_ORIGINS=https://cea.yourdomain.com,https://www.cea.yourdomain.com

# Content Security Policy settings
NEXT_PUBLIC_CSP_REPORT_URI=/api/csp-report

# Rate limiting configuration
RATE_LIMIT_REQUESTS_PER_MINUTE=100
RATE_LIMIT_WINDOW_MS=60000

# ---------------------------------------------------------------------------
# ANALYTICS AND MONITORING (Optional)
# ---------------------------------------------------------------------------

# Google Analytics
NEXT_PUBLIC_GA_MEASUREMENT_ID=G-XXXXXXXXXX

# PostHog analytics
NEXT_PUBLIC_POSTHOG_KEY=phc_XXXXXXXXXX